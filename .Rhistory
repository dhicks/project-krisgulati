View(ca_mid)
ca_doi <- oa_fetch(
doi = c("https://doi.org/10.1021/acsomega.1c04509"),
entity = "works",
verbose = TRUE
)
View(ca_doi)
View(ca_doi[[3]][[1]])
View(ca_doi[[3]][[1]])
View(ca_mid)
View(ca_mid[[5]][[1]])
View(ca_doi[[3]][[1]])
ca_oaid <- oa_fetch(
id = c("https://openalex.org/W3205403193"),
entity = "works",
verbose = TRUE
)
ca_oaid <- oa_fetch(
author.id = c("https://openalex.org/W3205403193"),
entity = "works",
verbose = TRUE
)
ca_oaid <- oa_fetch(
author.id = "https://openalex.org/W3205403193",
entity = "works",
verbose = TRUE
)
View(ca_mid)
View(ca_mid[[5]][[1]])
ca_oaid <- oa_fetch(
author.id = "https://openalex.org/A2154038508,
entity = "works",
ca_oaid <- oa_fetch(
author.id = "https://openalex.org/A2154038508",
entity = "works",
verbose = TRUE
)
View(ca_oaid)
View(ca_doi)
View(ca_doi[[3]][[1]])
ca_oaid <- oa_fetch(
author.id = "https://api.openalex.org/works?filter=author.id:A2154038508",
entity = "works",
verbose = TRUE
)
ca_oaid_alt <- oa_fetch(
author.id = "A2154038508",
entity = "works",
verbose = TRUE
)
ca_oaid <- oa_fetch(
author.id = "https://openalex.org/A2154038508",
entity = "works",
verbose = TRUE
)
ca_orcid <- oa_fetch(
entity = "works",
author.orcid = "https://orcid.org/0000-0001-5875-4380",
verbose = TRUE
)
View(ca_orcid)
rr <- oa_fetch(
entity = "authors",
display_name = c("Reginald L. Robinson"),
verbose = TRUE
)
View(rr)
View(rr[[5]][[1]])
View(rr[[5]][[1]])
View(rr[[5]][[1]])
View(rr[[5]][[2]])
View(rr[[9]][[1]])
View(rr[[9]][[4]])
tb <- oa_fetch(
entity = "authors",
display_name = c("Teresa Buchanan"),
verbose = TRUE
)
View(tb)
View(tb[[5]][[1]])
tb_doi <- oa_fetch(
doi = c("10.1177/1476718X14548781"),
entity = "works",
verbose = TRUE
)
View(tb_doi)
View(tb_doi[[3]][[1]])
tb_oaid_alt <- oa_fetch(
author.id = "A1976480720",
entity = "works",
verbose = TRUE
)
View(tb_oaid_alt)
View(tb_oaid_alt[[3]][[1]])
#install.packages("readr")
library(openalexR)
library(dplyr)
library(ggplot2)
library(jsonlite)
library(tidyverse)
library(readr)
options(openalexR.mailto = "kgulati@ucmerced.edu")
setwd("C:/Users/kgulati/Desktop/NewProject")
brucem_doi <- oa_fetch(
doi = c("https://doi.org/10.1029/2006GL026145"),
entity = "works",
verbose = TRUE
)
View(brucem_doi)
View(brucem_doi[[3]][[1]])
View(brucem_doi[[3]][[1]])
brucem_doi <- oa_fetch(
doi = c("https://doi.org/10.1029/2004EO470001"),
entity = "works",
verbose = TRUE
)
View(brucem_doi)
View(brucem_doi[[3]][[1]])
brucem_oa <- oa_fetch(
author.id = "A2162434754",
entity = "works",
verbose = TRUE
)
View(brucem_oa)
View(brucem_oa)
dougmac_doi <- oa_fetch(
doi = c("https://doi.org/10.1017/aog.2018.29"),
entity = "works",
verbose = TRUE
)
View(dougmac_doi)
View(dougmac_doi[[3]][[1]])
dougmac_oa <- oa_fetch(
author.id = "A336332055",
entity = "works",
verbose = TRUE
)
View(dougmac_oa)
andrewallen_doi <- oa_fetch(
doi = c("https://doi.org/10.1016/j.gene.2007.05.022"),
entity = "works",
verbose = TRUE
)
View(andrewallen_doi)
View(andrewallen_doi[[3]][[1]])
andrewallen_oa <- oa_fetch(
author.id = "A2111224977",
entity = "works",
verbose = TRUE
)
View(andrewallen_oa)
dbronk_doi <- oa_fetch(
doi = c("https://doi.org/10.5194/bg-4-283-2007, 2007"),
entity = "works",
verbose = TRUE
)
dbronk_doi <- oa_fetch(
doi = c("https://doi.org/10.5194/bg-4-283-2007"),
entity = "works",
verbose = TRUE
)
View(dbronk_doi)
View(dbronk_doi[[3]][[1]])
dbronk_oa <- oa_fetch(
author.id = "A2302953413",
entity = "works",
verbose = TRUE
)
View(dbronk_oa)
lgell_doi <- oa_fetch(
doi = c("https://doi.org/10.1080/00139157.2011.554501"),
entity = "works",
verbose = TRUE
)
View(lgell_doi)
View(lgell_doi[[3]][[1]])
lgell_oa <- oa_fetch(
author.id = "A2687000188",
entity = "works",
verbose = TRUE
)
View(lgell_oa)
gsullivan_doi <- oa_fetch(
doi = c("https://doi.org/10.48550/arXiv.0907.4183"),
entity = "works",
verbose = TRUE
)
dhutch_doi <- oa_fetch(
doi = c("https://doi.org/10.1111/gcb.14102"),
entity = "works",
verbose = TRUE
)
dhutch_doi <- oa_fetch(
doi = c("https://doi.org/10.1038/nclimate1507"),
entity = "works",
verbose = TRUE
)
View(dhutch_doi)
View(dhutch_doi[[3]][[1]])
dhutch_oa <- oa_fetch(
author.id = "A2473864025",
entity = "works",
verbose = TRUE
)
View(dhutch_oa)
rdetrick_doi <- oa_fetch(
doi = c("https://doi.org/10.1029/94JB02649"),
entity = "works",
verbose = TRUE
)
rdetrick_doi <- oa_fetch(
doi = c("https://doi.org/10.1029/94JB02649"),
entity = "works",
verbose = TRUE
)
View(rdetrick_doi)
igorkamen_doi <- oa_fetch(
doi = c("https://doi.org/10.1175/JCLI3689.1"),
entity = "works",
verbose = TRUE
)
View(igorkamen_doi)
View(igorkamen_doi[[3]][[1]])
igorkamen_oa <- oa_fetch(
author.id = "A2607683622",
entity = "works",
verbose = TRUE
)
View(igorkamen_oa)
pmorin_doi <- oa_fetch(
doi = c("https://doi.org/10.5194/tc-13-665-2019"),
entity = "works",
verbose = TRUE
)
View(pmorin_doi)
View(pmorin_doi[[3]][[1]])
pmorin_oa <- oa_fetch(
author.id = "A2133989406",
entity = "works",
verbose = TRUE
)
View(pmorin_oa)
lquet_doi <- oa_fetch(
doi = c("https://doi.org/10.1098/rstb.2006.1955"),
entity = "works",
verbose = TRUE
)
View(lquet_doi)
View(lquet_doi[[3]][[1]])
lquet_oa <- oa_fetch(
author.id = "A2922975525",
entity = "works",
verbose = TRUE
)
View(lquet_oa)
lquet_doi <- oa_fetch(
doi = c("10.3354/meps10965"),
entity = "works",
verbose = TRUE
)
View(lquet_oa)
View(lquet_doi)
View(lquet_doi[[3]][[1]])
lquet_oa <- oa_fetch(
author.id = "A225980128",
entity = "works",
verbose = TRUE
)
View(lquet_oa)
jwhite_doi <- oa_fetch(
doi = c("https://doi.org/10.1002/jqs.622"),
entity = "works",
verbose = TRUE
)
View(jwhite_doi)
View(jwhite_doi[[3]][[1]])
jwhite_oa <- oa_fetch(
author.id = "A2435981389",
entity = "works",
verbose = TRUE
)
View(jwhite_oa)
greghak_doi <- oa_fetch(
doi = c("https://doi.org/10.1175/2007MWR2132.1"),
entity = "works",
verbose = TRUE
)
View(greghak_doi)
View(greghak_doi[[3]][[1]])
greghak_oa <- oa_fetch(
author.id = "A2018116547",
entity = "works",
verbose = TRUE
)
View(greghak_oa)
esteig_doi <- oa_fetch(
doi = c("https://doi.org/10.1016/j.yqres.2004.07.001"),
entity = "works",
verbose = TRUE
)
View(esteig_doi)
View(esteig_doi[[3]][[1]])
esteig_oa <- oa_fetch(
author.id = "A23023797",
entity = "works",
verbose = TRUE
)
View(esteig_oa)
View(esteig_oa)
class(esteig_oa)
class(esteig_oa$author)
View(esteig_oa[[3]][[1]])
jchen_doi <- oa_fetch(
doi = c("https://doi.org/10.1029/2004GL020873"),
entity = "works",
verbose = TRUE
)
View(jchen_doi)
View(jchen_doi[[3]][[1]])
jchen_oa <- oa_fetch(
author.id = "A2474043143",
entity = "works",
verbose = TRUE
)
View(jchen_oa)
maydin_doi <- oa_fetch(
doi = c("https://doi.org/10.1029/2019GL085101"),
entity = "works",
verbose = TRUE
)
View(maydin_doi)
View(maydin_doi[[3]][[1]])
maydin_oa <- oa_fetch(
author.id = "A2475841261",
entity = "works",
verbose = TRUE
)
View(maydin_oa)
mbraun_doi <- oa_fetch(
doi = c("http://dx.doi.org/10.5194/essd-14-4287-2022"),
entity = "works",
verbose = TRUE
)
mbraun_doi <- oa_fetch(
doi = c("http://dx.doi.org/10.1029/2020GL091311"),
entity = "works",
verbose = TRUE
)
mbraun_doi <- oa_fetch(
doi = c("http://dx.doi.org/10.3390/rs9060635"),
entity = "works",
verbose = TRUE
)
mbraun_doi <- oa_fetch(
doi = c("https://doi.org/10.3390/rs9050478"),
entity = "works",
verbose = TRUE
)
View(mbraun_doi)
View(mbraun_doi[[3]][[1]])
mbraun_oa <- oa_fetch(
author.id = "A2112234690",
entity = "works",
verbose = TRUE
)
View(mbraun_oa)
#################################### Cleaner Script ######################################
##########################################################################################
##########################################################################################
library(openalexR)
library(dplyr)
library(ggplot2)
library(jsonlite)
library(tidyverse)
library(readr)
options(openalexR.mailto = "kgulati@ucmerced.edu")
setwd("C:/Users/kgulati/Desktop/NewProject")
#################################### Step One: Find Authors' ORCID/OA ID #################
##########################################################################################
##########################################################################################
# Bring in the authors -- this process is a manual process in the util file where I find the authors ORCID and/or OA ID
source("utils/import-authors.R")
list_dfs <- import_Authors() # Assign the util file to a list. We have a list of dataframes
incident_year <- c("austin_holland"=2013, "aline_gubrium" = 2014, "bart" = 2015, "ron" = 2011, "michael" = 2010)
# If you want to view one of the dfs
#View(list_dfs[[1]])
#################################### Step Two: Clean the Authors' data #################
##########################################################################################
##########################################################################################
# But, the list of dataframes is fairly noisy, i.e. duplicates etc. So, we want to clean all of them!
clean_dfs <- lapply(list_dfs, function(df){
print(class(df))
df_clean <- df %>% drop_na(doi) # Drop if there's no doi
df_clean <- df_clean[(df_clean$type == "journal-article") ,] # Drop if the paper isn't categorised as a journal article
# df_clean <- df_clean[complete.cases(df_clean[,c("volume","issue")]),]
# I've commented this out because I don't think we need it for now because later I'll focus on page numbers and ISSN numbers.
df_clean <- df_clean %>% drop_na(type) # Drop, if the type is considered as na
df_clean <- df_clean %>% drop_na(issn) # Drop if there's no ISSN number, which we need later
df_clean[, "issn_clean"] <- sapply(df_clean$issn, "[[", 1) # We just take the first ISSN number, and create a new column for this
return(df_clean)
})
names(clean_dfs) = names(list_dfs)
#View(clean_dfs[[1]])
#View(clean_dfs[[2]])
#View(clean_dfs[[3]])
#View(clean_dfs[[4]])
#View(clean_dfs[[5]])
#################################### Step Three: Create Control Group #################
##########################################################################################
##########################################################################################
# Create a function to sandwich the particular publication in question, to extract all other articles from that place
# Take an author, find all the other authors that published in the same day (capturing same volume)
source("utils/create_control.R")
### Apply that function to every publication in the treatment group
all_data <- data.frame()
### Read file if all_data if it exists, otherwise go on with the for loop below
#write_csv(all_data, "Outputs/all_data.csv", na = "")
#all_data_temp <- read_delim("Outputs/all_data.csv", delim=",")
#If (!“filename” %in% list.files(“file path”) { …then do loop }
for (j in 1:length(clean_dfs)){
cat("getting author ", names(clean_dfs)[j], " " , j,  " of", length(clean_dfs), "\n")
for (i in 1:nrow(clean_dfs[[j]])) {
cat("\tgetting publications : ", i, " of", nrow(clean_dfs[[j]]), "\n")
issn <- clean_dfs[[j]]$issn_clean[i]
to_date <- clean_dfs[[j]]$publication_date[i]
from_date <- clean_dfs[[j]]$publication_date[i]
paper_id <- clean_dfs[[j]]$id[i]
control_group <- create_control(issn, to_date, from_date)
control_group[, "author_link"] <- names(clean_dfs)[j]
control_group[, "issn_link"] <- issn
control_group[, "treatment_link"] <- paper_id
control_group[, "treatment_or_control"] <- control_group$id %in% paper_id
control_group <- control_group %>% drop_na(doi) # Drop if there's no doi
control_group <- control_group[(control_group$type == "journal-article") ,] # Drop if the paper isn't categorised as a journal article
control_group <- control_group %>% drop_na(type) # Drop, if the type is considered as na
control_group <- control_group %>% drop_na(issn) # Drop if there's no ISSN number, which we need later
control_group[, "issn_clean"] <- sapply(control_group$issn, "[[", 1) # We just take the first ISSN number, and create a new column for this
control_group <- control_group %>%
filter(!is.na(counts_by_year))
### Step One: Initialise year columns
new_cols <- paste0("citations_n_", 1960:2022)
control_group[, new_cols] <- 0
### Step Two: Populate the columns with citations year-by-year
# Go to counts_by_year col in control_group df, we go to the first row, then for every row within the df
# populate the year with the citation number
if (nrow(control_group) > 0) {
for (k in 1:nrow(control_group)){
year_new_cols <- paste0("citations_n_", control_group$counts_by_year[[k]]$year)
citation_values <- control_group$counts_by_year[[k]]$cited_by_count
control_group[k, year_new_cols] <- as.list(citation_values)
}
}
### Create caseid in control_group here
control_group[, "caseid"] <- j
### Add pre column here
### Create incident year column
control_group[, "incident_year"] <- incident_year[names(clean_dfs)[j]]
control_group[, "pre"] <- ifelse(control_group$publication_year < incident_year[names(clean_dfs)[j]], 1, 0)
all_data <- rbind(all_data, control_group)
Sys.sleep(1) ## If get errors from OA, change time.
}
}
########Step Four: Expand citations column to include citations per year #################
##########################################################################################
##########################################################################################
write_csv(all_data,"C:/Users/kgulati/Desktop/NewProject\\small_sample.csv")
#Figure out why control_group has gone to 0 :(
View(control_group)
cat("\tgetting publications : ", i, " of", nrow(clean_dfs[[j]]), "\n")
issn <- clean_dfs[[j]]$issn_clean[i]
to_date <- clean_dfs[[j]]$publication_date[i]
clean_dfs[[5]]
names(clean_dfs)[5]
issn <- clean_dfs[[j]]$issn_clean[i]
to_date <- clean_dfs[[j]]$publication_date[i]
from_date <- clean_dfs[[j]]$publication_date[i]
paper_id <- clean_dfs[[j]]$id[i]
control_group <- create_control(issn, to_date, from_date)
control_group[, "author_link"] <- names(clean_dfs)[j]
control_group[, "issn_link"] <- issn
control_group[, "treatment_link"] <- paper_id
control_group[, "treatment_or_control"] <- control_group$id %in% paper_id
control_group <- control_group %>% drop_na(doi) # Drop if there's no doi
control_group <- control_group[(control_group$type == "journal-article") ,] # Drop if the paper isn't categorised as a journal article
control_group <- control_group %>% drop_na(type) # Drop, if the type is considered as na
control_group <- control_group %>% drop_na(issn) # Drop if there's no ISSN number, which we need later
control_group[, "issn_clean"] <- sapply(control_group$issn, "[[", 1) # We just take the first ISSN number, and create a new column for this
control_group <- control_group %>%
filter(!is.na(counts_by_year))
control_group <- create_control(issn, to_date, from_date)
control_group[, "author_link"] <- names(clean_dfs)[j]
control_group[, "issn_link"] <- issn
control_group[, "treatment_link"] <- paper_id
control_group[, "treatment_or_control"] <- control_group$id %in% paper_id
View(control_group)
View(all_data)
all_data %>% filter(pre==1) %>% filter(incident_year > publication_year) %>% view()
all_data %>% filter(incident_year > publication_year) %>% select(publication_year, incident_year, pre) %>% View()
all_data %>% filter(incident_year > publication_year) %>% select(publication_year, incident_year, pre) %>% count(pre)
all_data %>% filter(incident_year <= publication_year) %>% View()
all_data %>% filter(incident_year <= publication_year) %>% select(publication_year, incident_year, pre) %>% View()
View(all_data)
View(all_data[[3]][[1]])
View(all_data[[3]][[2]])
View(all_data[[3]][[1]])
View(all_data[[3]][[1]])
View(all_data[[3]][[1]])
View(all_data[[18]][[1]])
View(all_data[[3]][[1]])
View(all_data[[3]][[1]])
lapply(all_data$author, function(x) return(nrow(x)))
sapply(all_data$author, function(x) return(nrow(x)))
